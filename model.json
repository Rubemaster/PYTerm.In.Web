{
    "format":"layers-model",
    "generatedBy":null,
    "convertedBy":"TensorFlow.js Converter v4.20.0",
    "modelTopology": {
        "model_config":{
            "class_name": "Model",
            "config": {
                "name": "tf_albert_model_1",
                "layers": [
                    {
                        "class_name": "InputLayer",
                        "config": {
                            "batch_input_shape": [null, 512],
                            "dtype": "float32",
                            "sparse": false,
                            "name": "input_1"
                        }
                    },
                    {
                        "class_name": "TFAlbertMainLayer",
                        "config": {
                            "name": "albert",
                            "trainable": true,
                            "dtype": "float32",
                            "embedding_size": 128,
                            "hidden_size": 768,
                            "num_hidden_layers": 12,
                            "num_attention_heads": 12,
                            "intermediate_size": 3072,
                            "hidden_act": "gelu",
                            "hidden_dropout_prob": 0.0,
                            "attention_probs_dropout_prob": 0.0,
                            "max_position_embeddings": 512,
                            "type_vocab_size": 2,
                            "initializer_range": 0.02,
                            "layer_norm_eps": 1e-12,
                            "pad_token_id": 0,
                            "position_embedding_type": "absolute"
                        }
                    }
                ]
            }
        }
    },
    "weightsManifest":[
       {
          "paths":[
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard1of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard2of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard3of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard4of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard5of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard6of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard7of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard8of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard9of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard10of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard11of12.bin",
        "https://raw.githubusercontent.com/Rubemaster/PYTerm.In.Web/main/group1-shard12of12.bin"
          ],
          "weights":[
             {
                "name":"tf_albert_model_1/albert/embeddings/word_embeddings/weight",
                "shape":[
                   30000,
                   128
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/embeddings/token_type_embeddings/embeddings",
                "shape":[
                   2,
                   128
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/embeddings/position_embeddings/embeddings",
                "shape":[
                   512,
                   128
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/embeddings/LayerNorm/gamma",
                "shape":[
                   128
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/embeddings/LayerNorm/beta",
                "shape":[
                   128
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/embedding_hidden_mapping_in/kernel",
                "shape":[
                   128,
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/embedding_hidden_mapping_in/bias",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/query/kernel",
                "shape":[
                   768,
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/query/bias",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/key/kernel",
                "shape":[
                   768,
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/key/bias",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/value/kernel",
                "shape":[
                   768,
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/value/bias",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/dense/kernel",
                "shape":[
                   768,
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/dense/bias",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/LayerNorm/gamma",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/attention/LayerNorm/beta",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/ffn/kernel",
                "shape":[
                   768,
                   3072
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/ffn/bias",
                "shape":[
                   3072
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/ffn_output/kernel",
                "shape":[
                   3072,
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/ffn_output/bias",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/full_layer_layer_norm/gamma",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/encoder/albert_layer_groups_._0/albert_layers_._0/full_layer_layer_norm/beta",
                "shape":[
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/pooler/kernel",
                "shape":[
                   768,
                   768
                ],
                "dtype":"float32"
             },
             {
                "name":"tf_albert_model_1/albert/pooler/bias",
                "shape":[
                   768
                ],
                "dtype":"float32"
             }
          ]
       }
    ]
 }
